{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Youssef Mohammed Abd El-Hai : 20200669**\n",
        "\n",
        "**Rina Khaled Ahmed Mortada   : 20201078**\n",
        "\n",
        "**Rawan Khaled Abd El-Monem   : 20201072**"
      ],
      "metadata": {
        "id": "xKV4TTh_aH4X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUPlff7gmnLm",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAwm036euoI3",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def predict(x, w, b):\n",
        "    y_pred = sigmoid(np.dot(x, w) + b)\n",
        "\n",
        "    y_pred[y_pred >= 0.5] = 1\n",
        "    y_pred[y_pred < 0.5] = 0\n",
        "\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb4Zmf_ucHxl",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def calculate_y_pred_regularized(x, w, b, lam = 0.1):\n",
        "    y_pred = sigmoid(np.dot(x, w) + b  + lam * np.sum(np.abs(w)))\n",
        "\n",
        "    y_pred[y_pred >= 0.5] = 1\n",
        "    y_pred[y_pred < 0.5] = 0\n",
        "\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHUiEEX8uqlA",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5st269JVZAG",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def standardize(data):\n",
        "  return (data - np.mean(data)) / (np.std(data) + sys.float_info.min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ww3cBLitum9Q",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def accuracy(y, y_hat):\n",
        "    return np.mean(y == y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pv3T1Xz5vDWo",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def Logistic_Regression(x, y, learning_rate = 0.1, iterations = 100):\n",
        "\n",
        "    w = random.rand(x.shape[1])\n",
        "    b = random.rand(1)\n",
        "\n",
        "    tolerance=0.00001\n",
        "\n",
        "    for i in range(iterations):\n",
        "        y_pred = predict(x, w, b)\n",
        "\n",
        "        if(np.mean((y-y_pred)**2)<tolerance):\n",
        "          break\n",
        "\n",
        "        dw = np.dot(x.T, (y_pred - y)) / len(x)\n",
        "        db = np.mean(y_pred - y)\n",
        "\n",
        "        w -= learning_rate * dw\n",
        "        b -= learning_rate * db\n",
        "\n",
        "    return w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMyyHH4SdOPO",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def Logistic_Regression_Regularized(x, y, learning_rate = 0.1, iterations = 100, lam = 0.1):\n",
        "\n",
        "    w = random.rand(x.shape[1])\n",
        "    b = random.rand(1)\n",
        "\n",
        "    tolerance=0.00001\n",
        "\n",
        "    for i in range(iterations):\n",
        "\n",
        "        y_pred = calculate_y_pred_regularized(x, w, b)\n",
        "\n",
        "        if(np.mean((y-y_pred)**2)<tolerance):\n",
        "            break\n",
        "\n",
        "        dw = (np.dot(x.T, (y_pred - y)) + np.where(w>0, lam, -lam) / len(x))\n",
        "        db = np.mean(y_pred - y)\n",
        "\n",
        "        w -= learning_rate * dw\n",
        "        b -= learning_rate * db\n",
        "\n",
        "    return w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYozAAlPM6pg",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def Log_Reg_Regularized_minibatch(x, y, learning_rate = 0.1, iterations = 100, lam = 0.1, batchsize=64):\n",
        "\n",
        "    w = random.rand(x.shape[1])\n",
        "    b = random.rand(1)\n",
        "\n",
        "    tolerance=0.00001\n",
        "\n",
        "    for i in range(iterations):\n",
        "\n",
        "        for j in range(int(x.shape[0]/batchsize)):\n",
        "\n",
        "            if((j+1)*batchsize > x.shape[0]):\n",
        "                xtrain = x[j*batchsize:]\n",
        "                ytrain = y[j*batchsize:]\n",
        "            else:\n",
        "                xtrain = x[j*batchsize:(j+1)*batchsize]\n",
        "                ytrain = y[j*batchsize:(j+1)*batchsize]\n",
        "\n",
        "            y_pred = calculate_y_pred_regularized(xtrain, w, b)\n",
        "\n",
        "            dw = (np.dot(xtrain.T, (y_pred - ytrain)) + np.where(w>0, lam, -lam) / len(x))\n",
        "            db = np.mean(y_pred - ytrain)\n",
        "\n",
        "            w -= learning_rate * dw\n",
        "            b -= learning_rate * db\n",
        "\n",
        "            # Testing the effect after each batch\n",
        "            y_pred = calculate_y_pred_regularized(x, w, b)\n",
        "            if(np.mean((y-y_pred)**2)<tolerance):\n",
        "                return w,b\n",
        "\n",
        "        y_pred = calculate_y_pred_regularized(x, w, b)\n",
        "        if(np.mean((y-y_pred)**2)<tolerance):\n",
        "            break\n",
        "\n",
        "    return w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTP5MqkGYTbh",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def Log_Reg_Regularized_minibatch_using_RMS_Prop_optimzer(x, y, learning_rate = 0.1, iterations = 100, lam = 0.1, batchsize=64, beta=0.999, epcilon = 1e-8):\n",
        "\n",
        "    w = random.rand(x.shape[1])\n",
        "    b = random.rand(1)\n",
        "\n",
        "    # Initialize Vdw for RMS_Prop optimizer\n",
        "    Vdw = 0\n",
        "    Vdb = 0\n",
        "\n",
        "    t = 1\n",
        "\n",
        "    tolerance=0.00001\n",
        "\n",
        "    for i in range(iterations):\n",
        "\n",
        "        for j in range(int(x.shape[0]/batchsize)):\n",
        "\n",
        "            if((j+1)*batchsize > x.shape[0]):\n",
        "                xtrain = x[j*batchsize:]\n",
        "                ytrain = y[j*batchsize:]\n",
        "            else:\n",
        "                xtrain = x[j*batchsize:(j+1)*batchsize]\n",
        "                ytrain = y[j*batchsize:(j+1)*batchsize]\n",
        "\n",
        "            y_pred = calculate_y_pred_regularized(xtrain, w, b)\n",
        "\n",
        "            dw = (np.dot(xtrain.T, (y_pred - ytrain)) + np.where(w>0, lam, -lam) / len(x))\n",
        "            db = np.mean(y_pred - ytrain)\n",
        "\n",
        "            # Update Vdw & Vdb\n",
        "            biased_Vdw = beta * Vdw + (1-beta) * (dw**2)\n",
        "            unbiased_Vdw = Vdw / (1-(beta**t))\n",
        "\n",
        "            biased_Vdb = beta * Vdb + (1-beta) * (db**2)\n",
        "            unbiased_Vdb = Vdb / (1-(beta**t))\n",
        "\n",
        "            # Update w & b\n",
        "            w -= learning_rate * (dw / (np.sqrt(unbiased_Vdw) + epcilon))\n",
        "            b -= learning_rate * (db / (np.sqrt(unbiased_Vdb) + epcilon))\n",
        "\n",
        "            # Testing the effect after each batch\n",
        "            y_pred = calculate_y_pred_regularized(x, w, b)\n",
        "            if(np.mean((y-y_pred)**2)<tolerance):\n",
        "                return w,b\n",
        "\n",
        "            # Times of weight update\n",
        "            t+=1\n",
        "\n",
        "        y_pred = calculate_y_pred_regularized(x, w, b)\n",
        "        if(np.mean((y-y_pred)**2)<tolerance):\n",
        "            break\n",
        "\n",
        "    return w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "506alQVFhOGH",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def Log_Reg_Regularized_minibatch_using_Adam_optimzer(x, y, learning_rate = 0.1, iterations = 100, lam = 0.1, batchsize=64, beta=0.999, epcilon = 1e-8):\n",
        "\n",
        "    w = random.rand(x.shape[1])\n",
        "    b = random.rand(1)\n",
        "\n",
        "    # Initialize Vdw for RMS_Prop optimizer\n",
        "    Vdw = 0\n",
        "    Vdb = 0\n",
        "\n",
        "    t = 1\n",
        "\n",
        "    tolerance=0.00001\n",
        "\n",
        "    for i in range(iterations):\n",
        "\n",
        "        for j in range(int(x.shape[0]/batchsize)):\n",
        "\n",
        "            if((j+1)*batchsize > x.shape[0]):\n",
        "                xtrain = x[j*batchsize:]\n",
        "                ytrain = y[j*batchsize:]\n",
        "            else:\n",
        "                xtrain = x[j*batchsize:(j+1)*batchsize]\n",
        "                ytrain = y[j*batchsize:(j+1)*batchsize]\n",
        "\n",
        "            y_pred = calculate_y_pred_regularized(xtrain, w, b)\n",
        "\n",
        "            dw = (np.dot(xtrain.T, (y_pred - ytrain)) + np.where(w>0, lam, -lam) / len(x))\n",
        "            db = np.mean(y_pred - ytrain)\n",
        "\n",
        "            # Update Vdw & Vdb\n",
        "            biased_Vdw = beta * Vdw + (1-beta) * (dw**2)\n",
        "            mdw= beta * Vdw + (1-beta) * (dw)\n",
        "            unbiased_Vdw = Vdw / (1-(beta**t))\n",
        "            unbiased_mdw=mdw / (1-(beta**t))\n",
        "\n",
        "            biased_Vdb = beta * Vdb + (1-beta) * (db**2)\n",
        "            mdb= beta * Vdb + (1-beta) * (db)\n",
        "            unbiased_Vdb = Vdb / (1-(beta**t))\n",
        "            unbiased_mdb=mdb / (1-(beta**t))\n",
        "\n",
        "            # Update w & b\n",
        "            w -= learning_rate * (unbiased_mdw / (np.sqrt(unbiased_Vdw) + epcilon))\n",
        "            b -= learning_rate * (unbiased_mdb / (np.sqrt(unbiased_Vdb) + epcilon))\n",
        "\n",
        "            # Testing the effect after each batch\n",
        "            y_pred = calculate_y_pred_regularized(x, w, b)\n",
        "            if(np.mean((y-y_pred)**2)<tolerance):\n",
        "                return w,b\n",
        "\n",
        "            # Times of weight update\n",
        "            t+=1\n",
        "\n",
        "        y_pred = calculate_y_pred_regularized(x, w, b)\n",
        "        if(np.mean((y-y_pred)**2)<tolerance):\n",
        "            break\n",
        "\n",
        "    return w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjDqYXeJg1xC",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/sample_data/mnist_train_small.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWbPtKcwTBmf",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "xtrain = data[data['6'].isin([0, 1])].drop(columns=['6'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ18tEb6RRm8",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "y_train = data[data['6'].isin([0, 1])]['6']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hVp0eU_QNpG",
        "outputId": "5906288c-787c-4ca4-d940-10178a6e333e",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3472: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "x_train = standardize(xtrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh_G3Chdrmv_",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "x_train, y_train = shuffle(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQ-zRxtkZgvN",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "validation_ratio = 0.2\n",
        "\n",
        "x_validation = x_train[:int(validation_ratio * x_train.shape[0])]\n",
        "y_validation = y_train[:int(validation_ratio * y_train.shape[0])]\n",
        "\n",
        "x_train = x_train[int(validation_ratio * x_train.shape[0]):]\n",
        "y_train = y_train[int(validation_ratio * y_train.shape[0]):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FXMZmNKfGEl",
        "outputId": "5dbce151-d5e8-41b1-97ac-79496bfba4dc",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-dc64dee5606b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.990487514863258"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "w1, b1 = Logistic_Regression_Regularized(x_train, y_train, learning_rate=0.1,  iterations=100, lam=0.1)\n",
        "\n",
        "y_pred1 = calculate_y_pred_regularized(x_validation, w1, b1, lam=0.1)\n",
        "\n",
        "acc1 = accuracy(y_validation, y_pred1)\n",
        "acc1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17HX8k9PmYqv",
        "outputId": "74a9066e-e8cb-4453-e7f3-5bebfb7e4b0b",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-dc64dee5606b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9476813317479191"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "w2, b2 = Logistic_Regression_Regularized(x_train, y_train, learning_rate=0.1,  iterations=100, lam=0.3)\n",
        "\n",
        "y_pred2 = calculate_y_pred_regularized(x_validation, w2, b2, lam=0.3)\n",
        "\n",
        "acc2 = accuracy(y_validation, y_pred2)\n",
        "acc2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I52doMo2M6pj",
        "outputId": "c8acb263-27a7-47f9-a22a-ef055fecedb8",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-dc64dee5606b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9916765755053508"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "w3, b3 = Log_Reg_Regularized_minibatch(x_train, y_train, learning_rate=0.1,  iterations=100, lam=0.1, batchsize=150)\n",
        "\n",
        "y_pred3 = calculate_y_pred_regularized(x_validation, w3, b3, lam=0.1)\n",
        "\n",
        "acc3 = accuracy(y_validation, y_pred3)\n",
        "acc3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hof255hSfzHi",
        "outputId": "a653a8a5-4540-40cb-fc4f-44c36a660a32",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-dc64dee5606b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9928656361474435"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "w4, b4 = Log_Reg_Regularized_minibatch_using_RMS_Prop_optimzer(x_train, y_train, learning_rate=0.1,  iterations=100, lam=0.1, batchsize=150)\n",
        "\n",
        "y_pred4 = calculate_y_pred_regularized(x_validation, w4, b4, lam=0.1)\n",
        "\n",
        "acc4 = accuracy(y_validation, y_pred4)\n",
        "acc4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OnElkkdn63O",
        "outputId": "bf13db10-a8c2-4ef9-a626-51890abb868b",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-dc64dee5606b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9821640903686087"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "w5, b5 = Log_Reg_Regularized_minibatch_using_Adam_optimzer(x_train, y_train, learning_rate=0.1,  iterations=100, lam=0.1, batchsize=150)\n",
        "\n",
        "y_pred5 = calculate_y_pred_regularized(x_validation, w5, b5, lam=0.1)\n",
        "\n",
        "acc5 = accuracy(y_validation, y_pred5)\n",
        "acc5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#diff batch size\n",
        "w6, b6 = Log_Reg_Regularized_minibatch(x_train, y_train, learning_rate=0.1,  iterations=100, lam=0.1, batchsize=50)\n",
        "\n",
        "y_pred7 = calculate_y_pred_regularized(x_validation, w6, b6, lam=0.1)\n",
        "\n",
        "acc7 = accuracy(y_validation, y_pred3)\n",
        "acc7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQQGrionLbfz",
        "outputId": "158321b3-3e76-41b2-8216-5a2d90914709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-dc64dee5606b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9916765755053508"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzWQkQ6TqPLr"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipXErXwHqUnV",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv('/content/sample_data/mnist_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DUMaurCrPNn",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "xtest = test_data[test_data['7'].isin([0, 1])].drop(columns=['7'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAJIrB9nrPNo",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "y_test = test_data[test_data['7'].isin([0, 1])]['7']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Sb-s6UQrPNo",
        "outputId": "3ede6587-c66a-4f1f-b998-96b9a3dfec5c",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3472: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "x_test = standardize(xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvaUt3PfrxS-",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "x_test, y_test = shuffle(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "506f96c5-bb69-4038-efdb-b2d6b1d1e885",
        "scrolled": true,
        "id": "HsWODsshUHHH"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-dc64dee5606b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9957446808510638"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "#L1 regularization lambda 0.1\n",
        "y_pred11 = calculate_y_pred_regularized(x_test, w1, b1, lam=0.1)\n",
        "\n",
        "acc11 = accuracy(y_test, y_pred11)\n",
        "acc11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf4f6a3-f8e3-4458-ce7f-37b9a8abb604",
        "scrolled": true,
        "id": "KqhUNO24UHHN"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-dc64dee5606b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9513002364066194"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "#L1 regularization lambda 0.3\n",
        "y_pred12 = calculate_y_pred_regularized(x_test, w2, b2, lam=0.3)\n",
        "\n",
        "acc12 = accuracy(y_test, y_pred12)\n",
        "acc12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8148533-b6f7-490e-f940-83615fe6329e",
        "scrolled": true,
        "id": "pBPA0rnoUHHN"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-dc64dee5606b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9976359338061466"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "#mini batch batch size 150\n",
        "y_pred13 = calculate_y_pred_regularized(x_test, w3, b3, lam=0.1)\n",
        "\n",
        "acc13 = accuracy(y_test, y_pred13)\n",
        "acc13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be3f5bee-8f3a-4f94-c761-bdec00764289",
        "scrolled": true,
        "id": "dyoDo68JUHHN"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-dc64dee5606b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9976359338061466"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "#RMS optimizer\n",
        "y_pred14 = calculate_y_pred_regularized(x_test, w4, b4, lam=0.1)\n",
        "\n",
        "acc14 = accuracy(y_test, y_pred14)\n",
        "acc14"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mini batch batch size 50\n",
        "y_pred15 = calculate_y_pred_regularized(x_test, w6, b6, lam=0.1)\n",
        "\n",
        "acc15 = accuracy(y_test, y_pred15)\n",
        "acc15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d84b294-26da-4a6d-a9c4-de4875e99ecc",
        "id": "BI_MYPAvUHHN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-dc64dee5606b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9952718676122931"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsPPCpJ7r4sa",
        "outputId": "c4e78855-41a0-4c38-dd74-a6b4cb36fd84",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-dc64dee5606b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9905437352245863"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "#Adam optimizer\n",
        "y_pred16 = calculate_y_pred_regularized(x_test, w5, b5, lam=0.1)\n",
        "\n",
        "acc16 = accuracy(y_test, y_pred16)\n",
        "acc16"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# **Report**\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "\n",
        "Report the accuracies for all of the above cases and write a **conclusion** for each case\n",
        "explaining the behind reasons"
      ],
      "metadata": {
        "id": "lwKR5GKdHYdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **L1 Regularization**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "OEG9h7BsOdAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **L1 Regularization** with gradient descent optimizer:\n",
        " first lambda val 0.1"
      ],
      "metadata": {
        "id": "zC064zpSIjif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f' lambda = {0.1}\\n Accuracy = {acc11} ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-knPiU7KH3EB",
        "outputId": "2374bebe-259d-4e3f-e0d5-368f44bb548d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " lambda = 0.1\n",
            " Accuracy = 0.9957446808510638 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **L1 Regularization** with gradient descent optimizer:\n",
        " second lambda val 0.3"
      ],
      "metadata": {
        "id": "fA_JbYY4I4wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f' lambda = {0.3}\\n Accuracy = {acc12} ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qla-zrdZIjEp",
        "outputId": "42f1da9e-d98b-4894-a92f-e68c8abe2527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " lambda = 0.3\n",
            " Accuracy = 0.9513002364066194 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion** on *L1 Regularization* lambda values:\n",
        "\n",
        "\n",
        "> Smaller values like 0.1 is better than 0.3 and 0.5 because bigger values decrease the weights values more than needed that some important features have less effect on the data which decreases accuracy.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> Bigger values of lambda helps in decreasing the dependency on less important features and that is useful to avoid overfitting of data.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pVeFiLrPPCwI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Mini-Batch**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "PY3m5s4MOndd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mini-Batch** Regularized gradient descent optimizer:\n",
        "first size =150"
      ],
      "metadata": {
        "id": "MHVUFDQMJTsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f' lambda = {0.1}\\n batch size = {150}\\n Accuracy = {acc13} ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfdPkAV-Jfha",
        "outputId": "60eba187-d31a-4650-decc-6f52d7a02898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " lambda = 0.1\n",
            " batch size = 150\n",
            " Accuracy = 0.9976359338061466 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mini-Batch** Regularized gradient descent optimizer:\n",
        "first size =50"
      ],
      "metadata": {
        "id": "ED0O_1QUL3tS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f' lambda = {0.1}\\n batch size = {50}\\n Accuracy = {acc15} ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCSe58YRL5oS",
        "outputId": "97242762-cec6-47c2-9804-cd85d8365794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " lambda = 0.1\n",
            " batch size = 50\n",
            " Accuracy = 0.9952718676122931 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion** on *Mini-Batch* batch sizes:\n",
        "\n",
        "\n",
        "> In our case, larger batch sizes makes convergence for weights and the bias slower but more accurate while smaller batch sizes makes convergence for weights and the bias faster but less accurate.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u_uMUc4OQE7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optimizers**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "OvqsoasdO3MQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RMS** Prob optimizer"
      ],
      "metadata": {
        "id": "nGMx5LHAKfmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f' lambda = {0.1}\\n Accuracy = {acc14} ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5i71yJMKora",
        "outputId": "62524b74-b243-4481-a02a-5c9dd8baaf4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " lambda = 0.1\n",
            " Accuracy = 0.9976359338061466 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adam** optimizer"
      ],
      "metadata": {
        "id": "IDKdL_OAKykW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f' lambda = {0.1}\\n Accuracy = {acc16} ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6edQAAWyK7lO",
        "outputId": "3f4c40e6-adf5-4b10-e359-37c1a5cda914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " lambda = 0.1\n",
            " Accuracy = 0.9905437352245863 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion** on *Optimizers*:\n",
        "\n",
        "\n",
        ">In our case, RMS optimizer performed better than Adam optimizer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yzhza5RcTjap"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}